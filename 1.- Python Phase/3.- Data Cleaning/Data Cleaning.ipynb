{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b7ac120",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4975f93",
   "metadata": {},
   "source": [
    "With the information gathered during the [Data Survey](https://github.com/Donnie-McGee/Festival-Purchase-Behavior-Analysis/tree/main/1.-%20Python%20Phase/1.-%20Data%20Survey), I proceed to clean the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59620db5",
   "metadata": {},
   "source": [
    "### Removing non-essential fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1e4c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Festival Purchase Behavior Analysis\\Datasets\\festival_dataset_dirty_modified.csv\")\n",
    "\n",
    "df = df.drop([\n",
    "         \"hours_spent\",\n",
    "         \"ticket_price\",\n",
    "         \"stages_visited\",\n",
    "         \"attendee_id\",\n",
    "         \"entry_time\", \n",
    "         \"purchase_date\", \n",
    "         \"was_present\", \n",
    "         \"transport_used\",\n",
    "         \"top_artist_seen\", \n",
    "         \"origin_city\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e6f23c",
   "metadata": {},
   "source": [
    "### Change alphanumeric ticket_id to a numeric identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85e9404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a unique identifier for each row based on ticket_id\n",
    "# Factorize returns a tuple, but I only need the first element (the array of codes)\n",
    "# Smashes ticket_id values and assings indexes starting from one, taking care of duplicates\n",
    "df[\"ticket_id\"] = pd.factorize(df[\"ticket_id\"])[0] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bd69ea",
   "metadata": {},
   "source": [
    "### Null values handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3acc64ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender\n",
      "Female    7636\n",
      "Male      5359\n",
      "Other      866\n",
      "NaN        139\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "ticket_type\n",
      "3-day Pass    8158\n",
      "1-day Pass    2782\n",
      "VIP           2780\n",
      "NaN            280\n",
      "Name: count, dtype: int64\n",
      "---------------------------------\n",
      "gender\n",
      "Female    7716\n",
      "Male      5411\n",
      "Other      873\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "ticket_type\n",
      "3-day Pass    8323\n",
      "1-day Pass    2849\n",
      "VIP           2828\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- Gender column ---\n",
    "\n",
    "# Count the number of unique values in each column\n",
    "# Used to understand the dataset better\n",
    "print(df['gender'].value_counts(dropna=False))\n",
    "print(\"\\n\")\n",
    "\n",
    "# gender_dist will store the normalized distribution\n",
    "gender_dist = df[\"gender\"].value_counts(normalize=True)\n",
    "\n",
    "# mask will be used to locate the null values in the dataset\n",
    "mask = df[\"gender\"].isnull()\n",
    "\n",
    "# Adds all the null\n",
    "n_nulls = mask.sum()\n",
    "\n",
    "# Fill the null values with random choices based on the distribution\n",
    "# This will ensure that the null values are filled in a way that reflects the original distribution\n",
    "df.loc[mask, \"gender\"] = np.random.choice(\n",
    "    gender_dist.index,\n",
    "    size=n_nulls,\n",
    "    p=gender_dist.values\n",
    ")\n",
    "\n",
    "# --- Ticket Type column ---\n",
    "# Same steps to clean \"ticket_type\" column as we followed for \"gender\" column\n",
    "print(df[\"ticket_type\"].value_counts(dropna=False))\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "type_dist = df[\"ticket_type\"].value_counts(normalize=True)\n",
    "mask = df[\"ticket_type\"].isnull()\n",
    "n_nulls = mask.sum()\n",
    "df.loc[mask, \"ticket_type\"] = np.random.choice(\n",
    "    type_dist.index,\n",
    "    size = n_nulls,\n",
    "    p=type_dist.values\n",
    ")\n",
    "\n",
    "\n",
    "print(df[\"gender\"].value_counts(dropna=False))\n",
    "print(\"\\n\")\n",
    "print(df[\"ticket_type\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294be1dd",
   "metadata": {},
   "source": [
    "### Field rename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739de5ed",
   "metadata": {},
   "source": [
    "For better consistancy, \"satisfaction_score\" will be renamed \"satisfaction_rating\". This change will come in handy later on, in the [Data Modelling](https://github.com/Donnie-McGee/Festival-Purchase-Behavior-Analysis/tree/main/1.-%20Python%20Phase/4.-%20Data%20Modelling) phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecda09f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column for consistency\n",
    "df.rename({\"satisfaction_score\": \"satisfaction_rating\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c7579f",
   "metadata": {},
   "source": [
    "### Typos cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb3c1fc",
   "metadata": {},
   "source": [
    "During my [Data Survey](https://github.com/Donnie-McGee/Festival-Purchase-Behavior-Analysis/tree/main/1.-%20Python%20Phase/1.-%20Data%20Survey) I found these typos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdb09fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"payment_method\"] = df[\"payment_method\"].replace({\"cash \": \"Cash\"})\n",
    "df[\"favourite_genre\"] = df[\"favourite_genre\"].replace(\"hiphop\", \"Hip-Hop\")\n",
    "df[\"favourite_genre\"] = df[\"favourite_genre\"].replace(\"Regueton\", \"Reggaeton\")\n",
    "df[\"recommend_to_friend\"] = df[\"recommend_to_friend\"].replace({\"nO\": \"No\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8527fed",
   "metadata": {},
   "source": [
    "### Trimming values with spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05ec1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strips leading and trailing whitespace from all string columns\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "      # It will convert to string, then strip whitespace\n",
    "        df[col] = df[col].str.strip()\n",
    "      # It will replace multiple spaces with a single space\n",
    "        df[col] = df[col].str.replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4022b4e8",
   "metadata": {},
   "source": [
    "### Type convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72243454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With it, we ensure that the data types are appropriate for analysis and optimize memory usage\n",
    "df = df.astype({\n",
    "    'ticket_id': 'category',\n",
    "    'ticket_type': 'category',\n",
    "    'age': 'int',\n",
    "    'gender': 'category',\n",
    "    'group_size': 'int',\n",
    "    'food_expense': 'float',\n",
    "    'drink_expense': 'float',\n",
    "    'merch_expense': 'float',\n",
    "    'payment_method': 'category',\n",
    "    'favourite_genre': 'category',\n",
    "    'satisfaction_rating': 'int',\n",
    "    'security_rating': 'int',\n",
    "    'cleanliness_rating': 'int',\n",
    "    'recommend_to_friend': 'bool'\n",
    "})\n",
    "\n",
    "# Date conversion\n",
    "df['attendance_date'] = pd.to_datetime(df['attendance_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "083e8e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14000 entries, 0 to 13999\n",
      "Data columns (total 15 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   ticket_id            14000 non-null  category      \n",
      " 1   ticket_type          14000 non-null  category      \n",
      " 2   attendance_date      14000 non-null  datetime64[ns]\n",
      " 3   age                  14000 non-null  int64         \n",
      " 4   gender               14000 non-null  category      \n",
      " 5   group_size           14000 non-null  int64         \n",
      " 6   food_expense         14000 non-null  float64       \n",
      " 7   drink_expense        14000 non-null  float64       \n",
      " 8   merch_expense        14000 non-null  float64       \n",
      " 9   payment_method       14000 non-null  category      \n",
      " 10  favourite_genre      14000 non-null  category      \n",
      " 11  satisfaction_rating  14000 non-null  int64         \n",
      " 12  security_rating      14000 non-null  int64         \n",
      " 13  cleanliness_rating   14000 non-null  int64         \n",
      " 14  recommend_to_friend  14000 non-null  bool          \n",
      "dtypes: bool(1), category(5), datetime64[ns](1), float64(3), int64(5)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
