{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b7ac120",
   "metadata": {},
   "source": [
    "### Data Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d5ab58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14000, 26)\n",
      "\n",
      "\n",
      "Unnamed: 0               0\n",
      "ticket_id                0\n",
      "ticket_type            280\n",
      "ticket_price             0\n",
      "purchase_date            0\n",
      "attendance_date          0\n",
      "entry_time               0\n",
      "was_present              0\n",
      "attendee_id              0\n",
      "age                      0\n",
      "gender                  97\n",
      "origin_city              0\n",
      "transport_used           0\n",
      "group_size               0\n",
      "food_expense             0\n",
      "drink_expense            0\n",
      "merch_expense            0\n",
      "payment_method           0\n",
      "favourite_genre          0\n",
      "stages_visited           0\n",
      "top_artist_seen          0\n",
      "hours_spent              0\n",
      "satisfaction_score       0\n",
      "security_rating          0\n",
      "cleanliness_rating       0\n",
      "recommend_to_friend      0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "Unnamed: 0             14000\n",
      "ticket_id               9319\n",
      "ticket_type                3\n",
      "ticket_price               3\n",
      "purchase_date             89\n",
      "attendance_date            3\n",
      "entry_time               540\n",
      "was_present                1\n",
      "attendee_id             9319\n",
      "age                       42\n",
      "gender                     5\n",
      "origin_city                4\n",
      "transport_used             5\n",
      "group_size                 5\n",
      "food_expense            4703\n",
      "drink_expense           5414\n",
      "merch_expense           7497\n",
      "payment_method             4\n",
      "favourite_genre            6\n",
      "stages_visited             4\n",
      "top_artist_seen            5\n",
      "hours_spent              101\n",
      "satisfaction_score         4\n",
      "security_rating            4\n",
      "cleanliness_rating         4\n",
      "recommend_to_friend        2\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "Unique values of 'ticket_id':\n",
      "['TCK102187' 'TCK105186' 'TCK107469' ... 'TCK103587' 'TCK102589'\n",
      " 'TCK102375']\n",
      "\n",
      "Unique values of 'ticket_type':\n",
      "['3-day Pass' nan '1-day Pass' 'VIP']\n",
      "\n",
      "Unique values of 'purchase_date':\n",
      "['2025-03-07' '2025-02-06' '2025-03-08' '2025-04-30' '2025-02-18'\n",
      " '2025-02-26' '2025-04-13' '2025-03-12' '2025-02-28' '2025-02-13'\n",
      " '2025-03-15' '2025-04-05' '2025-03-01' '2025-04-03' '2025-02-04'\n",
      " '2025-04-14' '2025-02-02' '2025-02-19' '2025-04-27' '2025-03-03'\n",
      " '2025-03-29' '2025-02-24' '2025-02-17' '2025-04-23' '2025-02-21'\n",
      " '2025-02-27' '2025-03-28' '2025-04-06' '2025-03-10' '2025-02-11'\n",
      " '2025-04-01' '2025-02-01' '2025-02-12' '2025-04-24' '2025-04-12'\n",
      " '2025-04-17' '2025-04-02' '2025-03-26' '2025-03-13' '2025-03-20'\n",
      " '2025-03-17' '2025-03-18' '2025-02-15' '2025-04-08' '2025-03-30'\n",
      " '2025-03-06' '2025-02-23' '2025-03-19' '2025-02-09' '2025-03-22'\n",
      " '2025-04-28' '2025-04-26' '2025-03-27' '2025-04-18' '2025-02-03'\n",
      " '2025-04-21' '2025-03-24' '2025-02-25' '2025-04-19' '2025-03-02'\n",
      " '2025-02-10' '2025-04-29' '2025-04-20' '2025-03-05' '2025-03-14'\n",
      " '2025-04-07' '2025-04-25' '2025-02-22' '2025-02-14' '2025-03-04'\n",
      " '2025-03-31' '2025-03-23' '2025-03-16' '2025-04-04' '2025-03-21'\n",
      " '2025-04-09' '2025-02-08' '2025-03-09' '2025-04-22' '2025-04-10'\n",
      " '2025-04-16' '2025-02-05' '2025-04-15' '2025-02-07' '2025-02-20'\n",
      " '2025-03-25' '2025-02-16' '2025-04-11' '2025-03-11']\n",
      "\n",
      "Unique values of 'attendance_date':\n",
      "['2025-05-02' '2025-05-03' '2025-05-01']\n",
      "\n",
      "Unique values of 'entry_time':\n",
      "['19:22:00' '15:59:00' '16:32:00' '22:19:00' '19:35:00' '21:51:00'\n",
      " '22:24:00' '19:48:00' '21:27:00' '17:54:00' '15:15:00' '14:29:00'\n",
      " '16:31:00' '22:00:00' '17:24:00' '22:08:00' '15:05:00' '20:22:00'\n",
      " '19:09:00' '17:55:00' '15:10:00' '22:55:00' '16:00:00' '17:13:00'\n",
      " '19:36:00' '20:03:00' '15:40:00' '19:02:00' '18:55:00' '20:20:00'\n",
      " '18:35:00' '21:25:00' '16:47:00' '21:36:00' '22:52:00' '16:54:00'\n",
      " '22:48:00' '15:33:00' '21:55:00' '15:14:00' '16:19:00' '15:37:00'\n",
      " '17:38:00' '17:15:00' '18:12:00' '18:42:00' '20:26:00' '17:00:00'\n",
      " '20:35:00' '19:57:00' '14:08:00' '22:03:00' '18:18:00' '14:23:00'\n",
      " '20:18:00' '20:51:00' '17:19:00' '17:46:00' '17:45:00' '20:19:00'\n",
      " '16:48:00' '17:21:00' '16:25:00' '19:47:00' '16:37:00' '21:16:00'\n",
      " '19:40:00' '20:44:00' '18:14:00' '14:01:00' '20:13:00' '14:19:00'\n",
      " '16:58:00' '18:02:00' '22:01:00' '18:39:00' '16:50:00' '18:00:00'\n",
      " '18:59:00' '22:49:00' '14:07:00' '21:44:00' '18:07:00' '19:31:00'\n",
      " '17:59:00' '19:21:00' '20:40:00' '17:06:00' '21:09:00' '18:52:00'\n",
      " '19:39:00' '20:50:00' '21:04:00' '15:09:00' '17:53:00' '19:46:00'\n",
      " '17:05:00' '22:31:00' '22:15:00' '20:06:00' '14:51:00' '14:40:00'\n",
      " '15:34:00' '20:36:00' '20:00:00' '20:04:00' '21:10:00' '14:46:00'\n",
      " '20:37:00' '21:56:00' '18:09:00' '22:46:00' '14:33:00' '15:55:00'\n",
      " '15:08:00' '16:15:00' '14:44:00' '19:28:00' '14:21:00' '14:37:00'\n",
      " '15:26:00' '20:41:00' '20:58:00' '19:33:00' '20:02:00' '17:01:00'\n",
      " '17:08:00' '17:20:00' '16:09:00' '17:31:00' '21:38:00' '16:43:00'\n",
      " '17:11:00' '15:21:00' '16:57:00' '20:55:00' '19:08:00' '14:45:00'\n",
      " '15:54:00' '16:04:00' '21:50:00' '19:12:00' '18:29:00' '17:33:00'\n",
      " '18:23:00' '21:28:00' '21:18:00' '19:51:00' '16:36:00' '15:57:00'\n",
      " '22:20:00' '15:11:00' '22:12:00' '14:12:00' '20:45:00' '20:33:00'\n",
      " '16:21:00' '14:56:00' '21:48:00' '18:37:00' '16:05:00' '22:32:00'\n",
      " '21:52:00' '14:31:00' '14:54:00' '16:53:00' '21:01:00' '14:42:00'\n",
      " '14:06:00' '17:39:00' '14:52:00' '15:49:00' '15:20:00' '21:37:00'\n",
      " '22:38:00' '22:09:00' '18:13:00' '19:03:00' '17:58:00' '18:41:00'\n",
      " '22:37:00' '14:43:00' '15:35:00' '19:11:00' '20:21:00' '20:47:00'\n",
      " '14:20:00' '21:54:00' '21:32:00' '21:02:00' '20:29:00' '14:15:00'\n",
      " '19:14:00' '21:14:00' '22:25:00' '16:26:00' '18:49:00' '21:43:00'\n",
      " '16:35:00' '22:57:00' '16:12:00' '15:31:00' '16:18:00' '22:58:00'\n",
      " '16:39:00' '18:44:00' '20:05:00' '15:51:00' '18:01:00' '14:25:00'\n",
      " '20:59:00' '22:42:00' '14:55:00' '19:43:00' '15:27:00' '21:45:00'\n",
      " '21:58:00' '21:03:00' '15:42:00' '18:36:00' '20:49:00' '15:44:00'\n",
      " '18:58:00' '14:50:00' '15:56:00' '19:17:00' '21:11:00' '18:28:00'\n",
      " '15:23:00' '20:43:00' '17:17:00' '20:23:00' '19:38:00' '15:47:00'\n",
      " '21:35:00' '22:28:00' '19:53:00' '22:02:00' '15:46:00' '16:41:00'\n",
      " '22:13:00' '22:33:00' '22:36:00' '15:19:00' '18:48:00' '14:26:00'\n",
      " '14:35:00' '20:10:00' '15:22:00' '16:03:00' '19:19:00' '18:53:00'\n",
      " '19:07:00' '21:24:00' '22:10:00' '20:17:00' '15:38:00' '20:07:00'\n",
      " '14:59:00' '16:14:00' '16:24:00' '21:17:00' '19:20:00' '15:00:00'\n",
      " '17:07:00' '17:26:00' '19:32:00' '18:03:00' '18:20:00' '14:48:00'\n",
      " '16:22:00' '21:19:00' '16:46:00' '14:38:00' '17:49:00' '22:47:00'\n",
      " '18:46:00' '18:19:00' '22:45:00' '15:50:00' '18:31:00' '19:59:00'\n",
      " '20:54:00' '19:41:00' '15:04:00' '14:05:00' '15:13:00' '19:06:00'\n",
      " '19:50:00' '18:24:00' '16:02:00' '22:53:00' '21:00:00' '15:28:00'\n",
      " '14:27:00' '17:42:00' '22:05:00' '19:18:00' '21:08:00' '21:12:00'\n",
      " '16:17:00' '20:09:00' '17:41:00' '17:52:00' '22:35:00' '22:59:00'\n",
      " '21:39:00' '21:21:00' '14:28:00' '17:40:00' '20:15:00' '16:52:00'\n",
      " '20:48:00' '16:30:00' '15:01:00' '21:31:00' '19:54:00' '18:50:00'\n",
      " '16:44:00' '18:25:00' '16:16:00' '16:13:00' '21:30:00' '18:04:00'\n",
      " '21:07:00' '18:33:00' '17:56:00' '19:24:00' '18:43:00' '17:48:00'\n",
      " '15:58:00' '19:05:00' '17:14:00' '17:12:00' '19:55:00' '17:25:00'\n",
      " '19:27:00' '20:39:00' '16:51:00' '20:16:00' '22:43:00' '20:34:00'\n",
      " '19:56:00' '14:30:00' '19:52:00' '17:36:00' '16:10:00' '17:04:00'\n",
      " '21:06:00' '16:06:00' '19:42:00' '19:44:00' '16:28:00' '16:07:00'\n",
      " '19:04:00' '19:26:00' '21:13:00' '21:15:00' '20:30:00' '20:27:00'\n",
      " '17:23:00' '14:36:00' '20:11:00' '18:22:00' '22:51:00' '22:06:00'\n",
      " '22:23:00' '14:18:00' '17:34:00' '21:23:00' '16:27:00' '20:57:00'\n",
      " '21:33:00' '19:25:00' '21:46:00' '17:30:00' '21:59:00' '22:44:00'\n",
      " '14:04:00' '20:31:00' '18:54:00' '14:02:00' '16:23:00' '15:16:00'\n",
      " '20:25:00' '17:37:00' '21:29:00' '15:52:00' '21:22:00' '15:03:00'\n",
      " '21:26:00' '22:26:00' '15:39:00' '21:20:00' '22:50:00' '17:02:00'\n",
      " '21:34:00' '22:54:00' '16:01:00' '20:38:00' '14:57:00' '16:08:00'\n",
      " '16:45:00' '18:27:00' '19:49:00' '22:29:00' '17:16:00' '18:10:00'\n",
      " '21:49:00' '21:42:00' '17:35:00' '15:30:00' '22:17:00' '14:24:00'\n",
      " '21:40:00' '18:32:00' '20:42:00' '18:11:00' '15:53:00' '22:14:00'\n",
      " '22:11:00' '17:47:00' '18:08:00' '22:27:00' '14:10:00' '21:57:00'\n",
      " '20:14:00' '15:24:00' '20:46:00' '14:13:00' '14:32:00' '15:43:00'\n",
      " '16:34:00' '19:00:00' '16:11:00' '18:06:00' '14:39:00' '19:45:00'\n",
      " '20:24:00' '16:59:00' '19:29:00' '17:57:00' '15:17:00' '16:29:00'\n",
      " '14:09:00' '21:47:00' '18:30:00' '17:03:00' '20:53:00' '20:28:00'\n",
      " '18:51:00' '14:22:00' '16:42:00' '22:56:00' '22:41:00' '15:25:00'\n",
      " '19:10:00' '19:23:00' '22:39:00' '18:45:00' '22:22:00' '20:32:00'\n",
      " '15:18:00' '17:10:00' '14:17:00' '14:58:00' '19:30:00' '15:06:00'\n",
      " '20:56:00' '15:07:00' '22:34:00' '18:40:00' '14:14:00' '14:34:00'\n",
      " '21:53:00' '14:16:00' '15:36:00' '15:41:00' '18:15:00' '22:30:00'\n",
      " '17:28:00' '18:21:00' '21:41:00' '14:41:00' '14:03:00' '19:58:00'\n",
      " '19:15:00' '22:40:00' '18:16:00' '14:11:00' '16:40:00' '22:16:00'\n",
      " '18:38:00' '18:57:00' '18:05:00' '17:29:00' '19:37:00' '14:00:00'\n",
      " '14:49:00' '22:04:00' '17:27:00' '21:05:00' '20:01:00' '15:48:00'\n",
      " '17:18:00' '19:34:00' '17:43:00' '19:13:00' '17:51:00' '20:52:00'\n",
      " '18:56:00' '15:02:00' '16:33:00' '15:12:00' '14:53:00' '17:09:00'\n",
      " '22:18:00' '17:50:00' '15:45:00' '22:21:00' '18:34:00' '20:12:00'\n",
      " '16:56:00' '17:22:00' '16:38:00' '19:16:00' '22:07:00' '17:44:00'\n",
      " '19:01:00' '16:49:00' '18:17:00' '17:32:00' '15:32:00' '14:47:00'\n",
      " '18:26:00' '16:55:00' '20:08:00' '16:20:00' '15:29:00' '18:47:00']\n",
      "\n",
      "Unique values of 'attendee_id':\n",
      "['ATD202187' 'ATD205186' 'ATD207469' ... 'ATD203587' 'ATD202589'\n",
      " 'ATD202375']\n",
      "\n",
      "Unique values of 'gender':\n",
      "['Cash' 'Female' 'Male' 'Other' 'cash ' nan]\n",
      "\n",
      "Unique values of 'origin_city':\n",
      "['Madrid' 'Barcelona' 'Sevilla' 'Valencia']\n",
      "\n",
      "Unique values of 'transport_used':\n",
      "['Train' 'Car' 'Plane' 'Other' 'Bus']\n",
      "\n",
      "Unique values of 'payment_method':\n",
      "['Cash' 'Festival App' 'Card' 'cash ']\n",
      "\n",
      "Unique values of 'favourite_genre':\n",
      "['Pop' 'Rock' 'Hip-Hop' 'Reggaeton' 'hiphop' 'Electronic']\n",
      "\n",
      "Unique values of 'top_artist_seen':\n",
      "['Artist D' 'Artist A' 'Artist E' 'Artist C' 'Artist B']\n",
      "\n",
      "Unique values of 'recommend_to_friend':\n",
      "['Yes' 'nO']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\PC\\Desktop\\Estudio\\Analisis de Datos\\Proyectos\\Festival Purchase Behavior Analysis\\Datasets\\festival_dataset_dirty_modified.csv\")\n",
    "\n",
    "# This part of the code provides an overview of the dataset, spaced, so each function is easier to read.\n",
    "\n",
    "print(df.shape)\n",
    "print(\"\\n\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n\")\n",
    "print(df.duplicated().sum())\n",
    "print(\"\\n\")\n",
    "print(df.nunique())\n",
    "print(\"\\n\")\n",
    "\n",
    "# I'm selecting columns of type 'object' (text) or 'category' to analyze unique values in those columns.\n",
    "text_columns = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Displaying unique values for each text column\n",
    "# With it, we can see the unique values in each text column, which helps us understand the dataset better\n",
    "# And detect typos or inconsistencies in the data.\n",
    "for col in text_columns:\n",
    "    print(f\"\\nUnique values of '{col}':\")\n",
    "    print(df[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a687974",
   "metadata": {},
   "source": [
    "With this first glimpse we recognise:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710549b2",
   "metadata": {},
   "source": [
    "1. Columns \"gender\" and \"ticket_type\" have null values.\n",
    "2. No duplicated rows.\n",
    "3. Unnecesary columns.\n",
    "4. Typos in columns \"payment_method\", \"favourite_genre\", \"recommend_to_friend\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59620db5",
   "metadata": {},
   "source": [
    "### Removing non-essential fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e1e4c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"ticket_id\",\n",
    "         \"attendee_id\",\n",
    "         \"entry_time\", \n",
    "         \"purchase_date\", \n",
    "         \"was_present\", \n",
    "         \"transport_used\",\n",
    "         \"top_artist_seen\", \n",
    "         \"origin_city\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bd69ea",
   "metadata": {},
   "source": [
    "### Null values handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3acc64ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender\n",
      "Cash      3711\n",
      "Female    3131\n",
      "Male      3072\n",
      "Other     3062\n",
      "cash       927\n",
      "NaN         97\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "ticket_type\n",
      "3-day Pass    8158\n",
      "1-day Pass    2782\n",
      "VIP           2780\n",
      "NaN            280\n",
      "Name: count, dtype: int64\n",
      "---------------------------------\n",
      "gender\n",
      "Cash      3741\n",
      "Female    3151\n",
      "Male      3090\n",
      "Other     3084\n",
      "cash       934\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "ticket_type\n",
      "3-day Pass    8333\n",
      "VIP           2835\n",
      "1-day Pass    2832\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- Gender column ---\n",
    "\n",
    "# Count the number of unique values in each column\n",
    "# Used to understand the dataset better\n",
    "print(df['gender'].value_counts(dropna=False))\n",
    "print(\"\\n\")\n",
    "\n",
    "# gender_dist will store the normalized distribution\n",
    "gender_dist = df[\"gender\"].value_counts(normalize=True)\n",
    "\n",
    "# mask will be used to locate the null values in the dataset\n",
    "mask = df[\"gender\"].isnull()\n",
    "\n",
    "# Adds all the null\n",
    "n_nulls = mask.sum()\n",
    "\n",
    "# Fill the null values with random choices based on the distribution\n",
    "# This will ensure that the null values are filled in a way that reflects the original distribution\n",
    "df.loc[mask, \"gender\"] = np.random.choice(\n",
    "    gender_dist.index,\n",
    "    size=n_nulls,\n",
    "    p=gender_dist.values\n",
    ")\n",
    "\n",
    "# --- Ticket Type column ---\n",
    "# Same steps to clean \"ticket_type\" column as we followed for \"gender\" column\n",
    "print(df[\"ticket_type\"].value_counts(dropna=False))\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "type_dist = df[\"ticket_type\"].value_counts(normalize=True)\n",
    "mask = df[\"ticket_type\"].isnull()\n",
    "n_nulls = mask.sum()\n",
    "df.loc[mask, \"ticket_type\"] = np.random.choice(\n",
    "    type_dist.index,\n",
    "    size = n_nulls,\n",
    "    p=type_dist.values\n",
    ")\n",
    "\n",
    "\n",
    "print(df[\"gender\"].value_counts(dropna=False))\n",
    "print(\"\\n\")\n",
    "print(df[\"ticket_type\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef50cb42",
   "metadata": {},
   "source": [
    "### Making *\"ticket_price\"* consistent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cf5722",
   "metadata": {},
   "source": [
    "In the original dataset the prices have been assigned inconsistently. For example, some entries labeled as “VIP” have a price of 80, and some “1-Day” tickets show a price of 350. \n",
    "\n",
    "This code ensures that, regardless of how they appeared in the raw data, all “1-Day” tickets become 80, all “3-Day” tickets become 210, and all “VIP” tickets become 350."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54e662c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will fix inconsistencies in the ticket prices\n",
    "# I will make sure that each ticket type has its corresponding price\n",
    "for i in range(len(df)):\n",
    "    if df.loc[i, \"ticket_type\"] == '1-Day':\n",
    "        df.loc[i, \"ticket_price\"] = 80\n",
    "    elif df.loc[i, \"ticket_type\"] == '3-Day':\n",
    "        df.loc[i, \"ticket_price\"] = 210\n",
    "    elif df.loc[i, \"ticket_type\"] == 'VIP':\n",
    "        df.loc[i, \"ticket_price\"] = 350"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c7579f",
   "metadata": {},
   "source": [
    "### Typos cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb3c1fc",
   "metadata": {},
   "source": [
    "During my *Data Survey* I found these typos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdb09fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"payment_method\"] = df[\"payment_method\"].replace({\"cash \": \"Cash\"})\n",
    "df[\"favourite_genre\"] = df[\"favourite_genre\"].replace(\"hiphop\", \"Hip-Hop\")\n",
    "df[\"favourite_genre\"] = df[\"favourite_genre\"].replace(\"Regueton\", \"Reggaeton\")\n",
    "df[\"recommend_to_friend\"] = df[\"recommend_to_friend\"].replace({\"nO\": \"No\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8527fed",
   "metadata": {},
   "source": [
    "### Trimming values with spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05ec1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strips leading and trailing whitespace from all string columns\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "      # It will convert to string, then strip whitespace\n",
    "        df[col] = df[col].str.strip()\n",
    "      # It will replace multiple spaces with a single space\n",
    "        df[col] = df[col].str.replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4022b4e8",
   "metadata": {},
   "source": [
    "### Type convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72243454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With it, we ensure that the data types are appropriate for analysis and optimize memory usage\n",
    "df = df.astype({\n",
    "    'ticket_type': 'category',\n",
    "    'ticket_price': 'int',\n",
    "    'age': 'int',\n",
    "    'gender': 'category',\n",
    "    'group_size': 'int',\n",
    "    'food_expense': 'float',\n",
    "    'drink_expense': 'float',\n",
    "    'merch_expense': 'float',\n",
    "    'payment_method': 'category',\n",
    "    'favourite_genre': 'category',\n",
    "    'stages_visited': 'int',\n",
    "    'satisfaction_score': 'int',\n",
    "    'security_rating': 'int',\n",
    "    'cleanliness_rating': 'int',\n",
    "    'recommend_to_friend': 'bool'\n",
    "})\n",
    "\n",
    "# Date conversion\n",
    "df['attendance_date'] = pd.to_datetime(df['attendance_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "083e8e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14000 entries, 0 to 13999\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   Unnamed: 0           14000 non-null  int64         \n",
      " 1   ticket_type          14000 non-null  category      \n",
      " 2   ticket_price         14000 non-null  int64         \n",
      " 3   attendance_date      14000 non-null  datetime64[ns]\n",
      " 4   age                  14000 non-null  int64         \n",
      " 5   gender               14000 non-null  category      \n",
      " 6   group_size           14000 non-null  int64         \n",
      " 7   food_expense         14000 non-null  float64       \n",
      " 8   drink_expense        14000 non-null  float64       \n",
      " 9   merch_expense        14000 non-null  float64       \n",
      " 10  payment_method       14000 non-null  category      \n",
      " 11  favourite_genre      14000 non-null  category      \n",
      " 12  stages_visited       14000 non-null  int64         \n",
      " 13  hours_spent          14000 non-null  float64       \n",
      " 14  satisfaction_score   14000 non-null  int64         \n",
      " 15  security_rating      14000 non-null  int64         \n",
      " 16  cleanliness_rating   14000 non-null  int64         \n",
      " 17  recommend_to_friend  14000 non-null  bool          \n",
      "dtypes: bool(1), category(4), datetime64[ns](1), float64(4), int64(8)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
